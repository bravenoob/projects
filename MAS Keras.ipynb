{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Workbook\n\n| Date       | Version   | Description                                      | Train score | Public score  | Commit Version\n|--------------------------------------------------------------------------------------------------------------------------------------------|\n| 2019-06-01 | v1.0        | resnet50 transfer learning, loss='categorical_crossentropy'  | - | -  | v6 |\n| 2019-06-07 | v1.1        | resnet50 transfer learning,  kappa scoree  |  - | -| v7 |\n"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Load the extension and start TensorBoard\n\n%load_ext tensorboard.notebook\n%tensorboard --logdir logs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/petfinder-adoption-prediction/train/train.csv\")\ntrain_data_dir = '../input/petfinder-train-keras/petfinder_train_keras/train_img'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip uninstall wrapt\n!pip install wrapt==1.11.1","execution_count":3,"outputs":[{"output_type":"stream","text":"\u001b[31mCannot uninstall 'wrapt'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\nCollecting wrapt==1.11.1\nInstalling collected packages: wrapt\n  Found existing installation: wrapt 1.10.11\n\u001b[31mCannot uninstall 'wrapt'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\n\u001b[33mYou are using pip version 19.0.3, however version 19.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import keras\n#import tensorflow as tf\n#from keras import backend as K\n\n#print(keras.__version__)\n#print(tf.__version__)\n\n!pip install --ignore-installed tensorflow==2.0.0-beta0\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\nfrom tensorflow.keras import Model\n\nprint(tf.VERSION)","execution_count":6,"outputs":[{"output_type":"stream","text":"Collecting tensorflow==2.0.0-beta0\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/19/0d0c7f240db7bcd6b83783b9a89a67f38584d100e23ad5ae93114be92232/tensorflow-2.0.0b0-cp36-cp36m-manylinux1_x86_64.whl (87.9MB)\n\u001b[K    100% |████████████████████████████████| 87.9MB 122kB/s eta 0:00:01\n\u001b[?25hCollecting wheel>=0.26 (from tensorflow==2.0.0-beta0)\n  Using cached https://files.pythonhosted.org/packages/bb/10/44230dd6bf3563b8f227dbf344c908d412ad2ff48066476672f3a72e174e/wheel-0.33.4-py2.py3-none-any.whl\nCollecting gast>=0.2.0 (from tensorflow==2.0.0-beta0)\nCollecting keras-preprocessing>=1.0.5 (from tensorflow==2.0.0-beta0)\n  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\nCollecting astor>=0.6.0 (from tensorflow==2.0.0-beta0)\n  Using cached https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\nCollecting absl-py>=0.7.0 (from tensorflow==2.0.0-beta0)\nCollecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow==2.0.0-beta0)\n  Using cached https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl\nCollecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow==2.0.0-beta0)\n  Using cached https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl\nCollecting protobuf>=3.6.1 (from tensorflow==2.0.0-beta0)\n  Using cached https://files.pythonhosted.org/packages/d2/fb/29de8d08967f0cce1bb10b39846d836b0f3bf6776ddc36aed7c73498ca7e/protobuf-3.8.0-cp36-cp36m-manylinux1_x86_64.whl\nCollecting keras-applications>=1.0.6 (from tensorflow==2.0.0-beta0)\n  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\nCollecting six>=1.10.0 (from tensorflow==2.0.0-beta0)\n  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\nCollecting numpy<2.0,>=1.14.5 (from tensorflow==2.0.0-beta0)\n  Using cached https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl\nCollecting wrapt>=1.11.1 (from tensorflow==2.0.0-beta0)\nCollecting grpcio>=1.8.6 (from tensorflow==2.0.0-beta0)\n  Using cached https://files.pythonhosted.org/packages/99/83/18f374294bf34128a448ee2fae37651f943b0b5fa473b5b3aff262c15bf8/grpcio-1.21.1-cp36-cp36m-manylinux1_x86_64.whl\nCollecting google-pasta>=0.1.6 (from tensorflow==2.0.0-beta0)\n  Using cached https://files.pythonhosted.org/packages/d0/33/376510eb8d6246f3c30545f416b2263eee461e40940c2a4413c711bdf62d/google_pasta-0.1.7-py3-none-any.whl\nCollecting termcolor>=1.1.0 (from tensorflow==2.0.0-beta0)\nCollecting markdown>=2.6.8 (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0)\n  Using cached https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl\nCollecting werkzeug>=0.11.15 (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0)\n  Using cached https://files.pythonhosted.org/packages/9f/57/92a497e38161ce40606c27a86759c6b92dd34fcdb33f64171ec559257c02/Werkzeug-0.15.4-py2.py3-none-any.whl\nCollecting setuptools>=41.0.0 (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0)\n  Using cached https://files.pythonhosted.org/packages/ec/51/f45cea425fd5cb0b0380f5b0f048ebc1da5b417e48d304838c02d6288a1e/setuptools-41.0.1-py2.py3-none-any.whl\nCollecting h5py (from keras-applications>=1.0.6->tensorflow==2.0.0-beta0)\n  Using cached https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl\n\u001b[31mpytest-cov 2.6.1 has requirement pytest>=3.6, but you'll have pytest 3.5.1 which is incompatible.\u001b[0m\n\u001b[31mmxnet-cu100 1.4.0.post0 has requirement numpy<1.15.0,>=1.8.2, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n\u001b[31mlime 0.1.1.33 has requirement matplotlib==2.1.0, but you'll have matplotlib 3.0.3 which is incompatible.\u001b[0m\n\u001b[31mkmeans-smote 0.1.2 has requirement imbalanced-learn<0.5,>=0.4.0, but you'll have imbalanced-learn 0.5.0.dev0 which is incompatible.\u001b[0m\n\u001b[31mkmeans-smote 0.1.2 has requirement numpy<1.16,>=1.13, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n\u001b[31manaconda-client 1.6.14 has requirement python-dateutil>=2.6.1, but you'll have python-dateutil 2.6.0 which is incompatible.\u001b[0m\nInstalling collected packages: wheel, gast, six, numpy, keras-preprocessing, astor, absl-py, setuptools, markdown, protobuf, werkzeug, grpcio, tb-nightly, tf-estimator-nightly, h5py, keras-applications, wrapt, google-pasta, termcolor, tensorflow\nSuccessfully installed absl-py-0.7.1 astor-0.8.0 gast-0.2.2 google-pasta-0.1.7 grpcio-1.21.1 h5py-2.9.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 numpy-1.16.4 protobuf-3.8.0 setuptools-41.0.1 six-1.12.0 tb-nightly-1.14.0a20190603 tensorflow-2.0.0b0 termcolor-1.1.0 tf-estimator-nightly-1.14.0.dev2019060501 werkzeug-0.15.4 wheel-0.33.4 wrapt-1.11.1\n\u001b[33mYou are using pip version 19.0.3, however version 19.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n1.13.1\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _cohen_kappa(y_true, y_pred, num_classes, weights=None, metrics_collections=None, updates_collections=None, name=None):\n   kappa, update_op = tf.contrib.metrics.cohen_kappa(y_true, y_pred,num_classes, weights, metrics_collections, updates_collections, name)\n   #K.get_session().run(tf.local_variables_initializer())\n   #with tf.control_dependencies([update_op]):\n      #kappa = tf.identity(kappa)\n   #return kappa\n   return update_op\n\ndef cohen_kappa_loss(num_classes, weights=None, metrics_collections=None, updates_collections=None, name=None):\n   def cohen_kappa(y_true, y_pred):\n      return -_cohen_kappa(y_true, y_pred, num_classes, weights, metrics_collections, updates_collections, name)\n   return cohen_kappa","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cohens_kappa(y_true, y_pred):\n    y_true_classes = tf.argmax(y_true, 1)\n    y_pred_classes = tf.argmax(y_pred, 1)\n    return tf.contrib.metrics.cohen_kappa(y_true_classes, y_pred_classes, 5)[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_weighted_loss():\n    def weighted_loss(y_true, y_pred):\n        return K.mean( K.square(y_pred - y_true) * K.exp(-K.log(1.7) * (K.log(1. + K.exp((y_true - 3)/5 )))),axis=-1  )\n    return weighted_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_kappa_loss(num_classes):\n    def my_kappa(y_true, y_pred):\n        #y_true_classes = tf.argmax(y_true, 1)\n        #y_pred_classes = tf.argmax(y_pred, 1)\n        y_true = K.flatten(y_true)          \n        y_pred = K.flatten(y_pred)\n        #y_true = K.cast(y_true, tf.float64)  \n        #y_pred = K.cast(y_pred, tf.float64)  \n        return -tf.contrib.metrics.cohen_kappa(y_true, y_pred, num_classes)[1]\n    return my_kappa","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cohens_kappa(y_true, y_pred):\n    y_true_classes = tf.argmax(y_true, 1)\n    y_pred_classes = tf.argmax(y_pred, 1)\n    return tf.contrib.metrics.cohen_kappa(y_true_classes, y_pred_classes, 5)[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from tf.keras.applications import ResNet50\n#from tf.keras.models import Sequential\n#from tf.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n\nnum_classes = 5\nmodel = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, pooling='avg')\n\nmy_new_model = tf.keras.models.Sequential()\nmy_new_model.add(model)\nmy_new_model.add(layers.Dense(num_classes, activation='softmax'))\n\n# Say not to train first layer (ResNet) model. It is already trained\nmy_new_model.layers[0].trainable = False\n\n# get the loss function and set parameters\nmodel_cohen_kappa = my_kappa_loss(num_classes=num_classes)\n\n#sgd Stochastic gradient descent optimizer\n#adam other\nmy_new_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[cohens_kappa])\n\nprint(my_new_model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tf.keras.utils import plot_model\nplot_model(my_new_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import TensorBoard\n\n\nimage_size = 224\nbatch_size = 64\nvalidation_split = 0.1\nnb_epochs = 20\n\n# steps_per_epoch: number of yields (batches) before a epoch is over\n# ceil(num_samples / batch_size)\n# epochs: Number of epochs to train the model. An epoch is an iteration over the entire data provided\n# class_weight: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). \n#  This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=validation_split) # set validation split\n\n#liefert die trainingsdaten als iterator\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(image_size, image_size),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training') # set as training data\n\n#liefert die Validationdaten als iterator\nvalidation_generator = train_datagen.flow_from_directory(\n    train_data_dir, # same directory as training data\n    target_size=(image_size, image_size),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation') # set as validation data\n\nSTEP_SIZE_TRAIN=math.ceil(train_generator.n//train_generator.batch_size)\nSTEP_SIZE_VALID=math.ceil(validation_generator.n//validation_generator.batch_size)\n\nprint(STEP_SIZE_TRAIN)\nprint(STEP_SIZE_VALID)\n\n\n# Configure the TensorBoard callback and fit the model\ntensorboard_callback = TensorBoard(\"logs\")\n\n#K.get_session().run(tf.local_variables_initializer())\n#K.get_session().run(tf.global_variables_initializer())\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n#sess.run(tf.local_variables_initializer())\n\nhistory = my_new_model.fit_generator(\n    train_generator,\n    steps_per_epoch = STEP_SIZE_TRAIN,\n    validation_data = validation_generator, \n    validation_steps = STEP_SIZE_VALID,\n    epochs = nb_epochs,\n    callbacks=[tensorboard_callback])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_training(history):\n    # Plot training & validation accuracy values\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()\n\n    # Plot training & validation loss values\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    plt.show()\n\n    plt.savefig('acc_vs_epochs.png')\n    \nplot_training(history)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}